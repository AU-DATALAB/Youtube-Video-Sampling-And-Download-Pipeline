{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c29bcc",
   "metadata": {},
   "source": [
    "# Pre-Download Data Processing\n",
    "\n",
    "This notebook handles the preprocessing of YouTube watch history data before the video download phase. It performs several crucial data cleaning and filtering steps to prepare the dataset for the video sampling and download pipeline.\n",
    "\n",
    "## Key Processing Steps:\n",
    "1. Import watch histories from participant JSON files\n",
    "2. Clean invalid or missing video IDs\n",
    "3. Filter videos within specified date range (2019-2024)\n",
    "4. Remove advertisements and YouTube Music entries\n",
    "5. Export cleaned dataset for the download pipeline\n",
    "\n",
    "## Requirements:\n",
    "- Input: Watch history JSON files in participant-specific format\n",
    "- Output: Cleaned CSV file ready for video sampling\n",
    "\n",
    "## Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c736dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install yt-dlp\n",
    "! pip install scenedetect\n",
    "! pip install opencv-python\n",
    "! pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee99b3c-2d6c-42b0-9f07-32dd12bbbee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import yt_dlp as yt\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import zipfile\n",
    "import sys\n",
    "import ffmpeg\n",
    "from datetime import datetime\n",
    "from download_utils import *\n",
    "\n",
    "sys.path.append('..')\n",
    "from ytutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce52ae7-82a3-4de8-9ac1-ba5631aa4281",
   "metadata": {},
   "source": [
    "## Sampling & Downloading\n",
    "\n",
    "### Watch-Histories Import\n",
    "- look into folder with watch-histories from Epinion in format [participant-id].json\n",
    "- import watch-histories as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68da85b-774d-445a-a3af-e897d8c90f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    This function creates one watch history dataframe from the inputted watch-history json files.\n",
      "    --- args ---\n",
      "    folder_path: string  # folder where watch-history files are located (.json)\n",
      "\n",
      "    --- kwargs ---\n",
      "    save_dataframe: bool  |  default: False\n",
      "\n",
      "    --- output ---\n",
      "    Outputs from function\n",
      "    watch_history: pandas.DataFrame\n",
      "\n",
      "    Outputs to current directory (if save_dataframe=True)\n",
      "    watch_history: .csv\n",
      "    \n",
      "Processing file 1077/1077\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Directory containg the JSON watch histories\n",
    "wh_directory = '../Survey_Data/Import_Date_2024_12_02/Watch_Data'  #directory with .json files\n",
    "path_wh = \"watch_history.csv\" #csv_path\n",
    "\n",
    "if not os.path.exists(path_wh):\n",
    "    print(loadEpinionData.__doc__)\n",
    "    all_wh = loadEpinionData(wh_directory, save_dataframe=True)\n",
    "else:\n",
    "    all_wh = pd.read_csv(path_wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b66ac68-b044-4ff8-aa36-d79db4f203fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dropped rows (%): 29164 (0.15%).\n"
     ]
    }
   ],
   "source": [
    "# Get the initial number of rows before filtering\n",
    "initial_row_count = len(all_wh)\n",
    "\n",
    "# Dropping rows where 'video_id' is NaN or empty string\n",
    "all_wh = all_wh[all_wh['video_id'].notna() & (all_wh['video_id'].str.strip() != '')]\n",
    "\n",
    "# Get the number of rows after filtering\n",
    "final_row_count = len(all_wh)\n",
    "\n",
    "# Ensuring Participant ID is regarded as str\n",
    "all_wh['Participant ID'] = all_wh['Participant ID'].astype(str)\n",
    "\n",
    "removed_n = initial_row_count - final_row_count\n",
    "removed_pc = (removed_n / initial_row_count) * 100\n",
    "\n",
    "# Print the number of dropped rows\n",
    "print(f\"Number of dropped rows (%): {removed_n} ({round(removed_pc, 2)}%).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3ff82-a781-4f55-851b-ecf573b0a326",
   "metadata": {},
   "source": [
    "## Subsetting for recent years\n",
    "- subset df for recent videos\n",
    "    - start date: 2019-07-01\n",
    "    - end date:   2024-06-30\n",
    "- output:\n",
    "    - output df\n",
    "    - length of input df\n",
    "    - length of output df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c5135c-f9f8-482c-9ea1-c1c2c3ca1d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos watched outside the range from July 1, 2019 to June 30, 2024 (%): 6076450 (31.88%).\n"
     ]
    }
   ],
   "source": [
    "# Define the date range: from July 1, 2019 to June 30, 2024\n",
    "start_date = '2019-07-01'  # '2019-07-01'\n",
    "end_date = '2024-06-30'    # '2024-06-30'\n",
    "\n",
    "\n",
    "# Subset the dataframe based on the date range\n",
    "last5_wh = all_wh[(all_wh['time'] >= start_date) & (all_wh['time'] <= end_date)]\n",
    "\n",
    "# Get the number of rows after subsetting\n",
    "last5_row_count = len(last5_wh)\n",
    "\n",
    "removed_n = final_row_count - last5_row_count\n",
    "removed_pc = (removed_n / len(all_wh)) * 100\n",
    "\n",
    "print(f\"Number of videos watched outside the range from July 1, 2019 to June 30, 2024 (%): {removed_n} ({round(removed_pc, 2)}%).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80081a7b-2878-4d6a-b296-448171837e49",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "- remove advertisements\n",
    "- remove yt-music entries\n",
    "- output:\n",
    "   - clean df\n",
    "   - metric on dropped ads in the new df\n",
    "   - metric on dropped music videos in the new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef95642f-4d93-4051-89ea-ec93f0410ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dropped advertisement entries (%): 2337818 (18.01%).\n",
      "Number of dropped non-43 char URLs (YT Music) (%): 565916 (4.36%).\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where the \"details\" column has a non-null entry (advertisement)\n",
    "no_ads_wh = last5_wh[last5_wh['details'].isna()]\n",
    "\n",
    "ads_n = len(last5_wh) - len(no_ads_wh)\n",
    "ads_pc = (ads_n / len(last5_wh)) * 100\n",
    "print(f\"Number of dropped advertisement entries (%): {ads_n} ({round(ads_pc,2)}%).\")\n",
    "\n",
    "\n",
    "clean_wh = no_ads_wh[no_ads_wh[\"url\"].apply(str).apply(len) <= 43]\n",
    "\n",
    "music_n = len(no_ads_wh) - len(clean_wh)\n",
    "music_pc = (music_n / len(last5_wh)) * 100\n",
    "print(f\"Number of dropped non-43 char URLs (YT Music) (%): {music_n} ({round(music_pc, 2)}%).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6839067-8c52-4df6-90cf-bd8c0b1ae97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean dataframe\n",
    "clean_wh.to_csv('clean_watch_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e4fc88-b67a-4943-a6cb-cab10f77dff1",
   "metadata": {},
   "source": [
    "### Move to \"Video_download_Pipeline.ipynb\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
