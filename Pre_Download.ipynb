{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce52ae7-82a3-4de8-9ac1-ba5631aa4281",
   "metadata": {},
   "source": [
    "# Sampling & Downloading\n",
    "\n",
    "## Watch-Histories Import\n",
    "- look into folder with watch-histories from Epinion in format [participant-id].json\n",
    "- import watch-histories as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f7d5945-2879-4e91-9f29-8c084bed8075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yt-dlp\n",
      "  Downloading yt_dlp-2025.1.26-py3-none-any.whl.metadata (172 kB)\n",
      "Downloading yt_dlp-2025.1.26-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "Installing collected packages: yt-dlp\n",
      "Successfully installed yt-dlp-2025.1.26\n",
      "Collecting scenedetect\n",
      "  Downloading scenedetect-0.6.5.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: Click in /opt/conda/lib/python3.12/site-packages (from scenedetect) (8.1.8)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from scenedetect) (2.2.1)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from scenedetect) (4.3.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from scenedetect) (4.67.1)\n",
      "Downloading scenedetect-0.6.5.2-py3-none-any.whl (127 kB)\n",
      "Installing collected packages: scenedetect\n",
      "Successfully installed scenedetect-0.6.5.2\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.12/site-packages (from opencv-python) (2.2.1)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "Collecting ffmpeg\n",
      "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ffmpeg\n",
      "  Building wheel for ffmpeg (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=6ba0be9285fa90405f8b8cc7f40db0798c734d765cf3d45a08f716642fe62920\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/26/21/0c/c26e09dff860a9071683e279445262346e008a9a1d2142c4ad\n",
      "Successfully built ffmpeg\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n"
     ]
    }
   ],
   "source": [
    "! pip install yt-dlp\n",
    "! pip install scenedetect\n",
    "! pip install opencv-python\n",
    "! pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee99b3c-2d6c-42b0-9f07-32dd12bbbee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import yt_dlp as yt\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import zipfile\n",
    "import sys\n",
    "import ffmpeg\n",
    "from datetime import datetime\n",
    "from download_utils import *\n",
    "\n",
    "sys.path.append('..')\n",
    "from ytutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68da85b-774d-445a-a3af-e897d8c90f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    This function creates one watch history dataframe from the inputted watch-history json files.\n",
      "    --- args ---\n",
      "    folder_path: string  # folder where watch-history files are located (.json)\n",
      "\n",
      "    --- kwargs ---\n",
      "    save_dataframe: bool  |  default: False\n",
      "\n",
      "    --- output ---\n",
      "    Outputs from function\n",
      "    watch_history: pandas.DataFrame\n",
      "\n",
      "    Outputs to current directory (if save_dataframe=True)\n",
      "    watch_history: .csv\n",
      "    \n",
      "Processing file 1077/1077\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Directory containg the JSON watch histories\n",
    "wh_directory = '../Survey_Data/Import_Date_2024_12_02/Watch_Data'  #directory with .json files\n",
    "path_wh = \"watch_history.csv\" #csv_path\n",
    "\n",
    "if not os.path.exists(path_wh):\n",
    "    print(loadEpinionData.__doc__)\n",
    "    all_wh = loadEpinionData(wh_directory, save_dataframe=True)\n",
    "else:\n",
    "    all_wh = pd.read_csv(path_wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b66ac68-b044-4ff8-aa36-d79db4f203fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dropped rows (%): 29164 (0.15%).\n"
     ]
    }
   ],
   "source": [
    "# Get the initial number of rows before filtering\n",
    "initial_row_count = len(all_wh)\n",
    "\n",
    "# Dropping rows where 'video_id' is NaN or empty string\n",
    "all_wh = all_wh[all_wh['video_id'].notna() & (all_wh['video_id'].str.strip() != '')]\n",
    "\n",
    "# Get the number of rows after filtering\n",
    "final_row_count = len(all_wh)\n",
    "\n",
    "# Ensuring Participant ID is regarded as str\n",
    "all_wh['Participant ID'] = all_wh['Participant ID'].astype(str)\n",
    "\n",
    "removed_n = initial_row_count - final_row_count\n",
    "removed_pc = (removed_n / initial_row_count) * 100\n",
    "\n",
    "# Print the number of dropped rows\n",
    "print(f\"Number of dropped rows (%): {removed_n} ({round(removed_pc, 2)}%).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3ff82-a781-4f55-851b-ecf573b0a326",
   "metadata": {},
   "source": [
    "## Subsetting for recent years\n",
    "- subset df for recent videos\n",
    "    - start date: 2019-07-01\n",
    "    - end date:   2024-06-30\n",
    "- output:\n",
    "    - output df\n",
    "    - length of input df\n",
    "    - length of output df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c5135c-f9f8-482c-9ea1-c1c2c3ca1d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos watched outside the range from July 1, 2019 to June 30, 2024 (%): 6076450 (31.88%).\n"
     ]
    }
   ],
   "source": [
    "# Define the date range: from July 1, 2019 to June 30, 2024\n",
    "start_date = '2019-07-01'  # '2019-07-01'\n",
    "end_date = '2024-06-30'    # '2024-06-30'\n",
    "\n",
    "\n",
    "# Subset the dataframe based on the date range\n",
    "last5_wh = all_wh[(all_wh['time'] >= start_date) & (all_wh['time'] <= end_date)]\n",
    "\n",
    "# Get the number of rows after subsetting\n",
    "last5_row_count = len(last5_wh)\n",
    "\n",
    "removed_n = final_row_count - last5_row_count\n",
    "removed_pc = (removed_n / len(all_wh)) * 100\n",
    "\n",
    "print(f\"Number of videos watched outside the range from July 1, 2019 to June 30, 2024 (%): {removed_n} ({round(removed_pc, 2)}%).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80081a7b-2878-4d6a-b296-448171837e49",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "- remove advertisements\n",
    "- remove yt-music entries\n",
    "- output:\n",
    "   - clean df\n",
    "   - metric on dropped ads in the new df\n",
    "   - metric on dropped music videos in the new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef95642f-4d93-4051-89ea-ec93f0410ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dropped advertisement entries (%): 2337818 (18.01%).\n",
      "Number of dropped non-43 char URLs (YT Music) (%): 565916 (4.36%).\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where the \"details\" column has a non-null entry (advertisement)\n",
    "no_ads_wh = last5_wh[last5_wh['details'].isna()]\n",
    "\n",
    "ads_n = len(last5_wh) - len(no_ads_wh)\n",
    "ads_pc = (ads_n / len(last5_wh)) * 100\n",
    "print(f\"Number of dropped advertisement entries (%): {ads_n} ({round(ads_pc,2)}%).\")\n",
    "\n",
    "\n",
    "clean_wh = no_ads_wh[no_ads_wh[\"url\"].apply(str).apply(len) <= 43]\n",
    "\n",
    "music_n = len(no_ads_wh) - len(clean_wh)\n",
    "music_pc = (music_n / len(last5_wh)) * 100\n",
    "print(f\"Number of dropped non-43 char URLs (YT Music) (%): {music_n} ({round(music_pc, 2)}%).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6839067-8c52-4df6-90cf-bd8c0b1ae97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean dataframe\n",
    "clean_wh.to_csv('clean_watch_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e4fc88-b67a-4943-a6cb-cab10f77dff1",
   "metadata": {},
   "source": [
    "### Move to Video_download_Pipeline.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
